{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB9UQy3_p07Y"
      },
      "outputs": [],
      "source": [
        "# Import Deep Learning Library\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Import Pretrained Model Library\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Import Dataset Preprocessing Library\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW3Me9wYzAye",
        "outputId": "42eff2f3-2e8a-4559-ae72-2ab265d9258e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "TRAIN_DIR = \"/content/drive/MyDrive/Project/Dataset/train\"\n",
        "VAL_DIR = \"/content/drive/MyDrive/Project/Dataset/val\"\n",
        "VAL_DIR = \"/content/drive/MyDrive/Project/Dataset/test\"\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "IMG_SIZE = (150, 150)\n",
        "NUM_CLASSES = 31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bIDoelD9ySa",
        "outputId": "6866db9d-7f7c-40da-bc0d-5d12c90ddfea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4557 files belonging to 31 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = (tf.keras.utils.image_dataset_from_directory(TRAIN_DIR,\n",
        "                                                            shuffle=True,\n",
        "                                                            batch_size=BATCH_SIZE,\n",
        "                                                            image_size=IMG_SIZE,\n",
        "                                                            label_mode='categorical',\n",
        "                                                            seed=90))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INT4IxQ7iKKp",
        "outputId": "565a4146-c51e-4d15-9b13-e17f4d527f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 992 files belonging to 31 classes.\n"
          ]
        }
      ],
      "source": [
        "val_dataset = tf.keras.utils.image_dataset_from_directory(VAL_DIR,\n",
        "                                                          shuffle=True,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          image_size=IMG_SIZE,\n",
        "                                                          label_mode='categorical',\n",
        "                                                          seed=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaZcTx5iiOMR",
        "outputId": "2759477d-a916-4e5d-9591-f96b1d270667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 992 files belonging to 31 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dataset = tf.keras.utils.image_dataset_from_directory(VAL_DIR,\n",
        "                                                          shuffle=True,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          image_size=IMG_SIZE,\n",
        "                                                          label_mode='categorical',\n",
        "                                                          seed=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2twKZegi0lb"
      },
      "outputs": [],
      "source": [
        "def create_augmentation_model():\n",
        "\n",
        "    augmentation_model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(150, 150, 3)),\n",
        "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "        tf.keras.layers.RandomRotation(0.2),\n",
        "        tf.keras.layers.RandomTranslation(0.1, 0.1),\n",
        "        tf.keras.layers.RandomZoom(0.2)\n",
        "    ])\n",
        "\n",
        "    return augmentation_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N58TcMbKjgJT"
      },
      "outputs": [],
      "source": [
        "def create_pre_trained_model():\n",
        "\n",
        "    pre_trained_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "        include_top=False,\n",
        "        input_shape=(150,150,3),\n",
        "        weights='imagenet'\n",
        "    )\n",
        "\n",
        "    # Make all the layers in the pre-trained model non-trainable\n",
        "    pre_trained_model.trainable = False\n",
        "\n",
        "    return pre_trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0JLHX4kkJDc"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "    augmentation_layers = create_augmentation_model()\n",
        "    pre_trained_model = create_pre_trained_model()\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(150,150,3))\n",
        "    augmented = augmentation_layers(inputs)\n",
        "    rescaled = tf.keras.layers.Rescaling(1./255)(augmented)\n",
        "\n",
        "    x = pre_trained_model(rescaled)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.15)(x)\n",
        "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "    predictions = tf.keras.layers.Dense(31, activation='softmax')(x)\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0005),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KCj1fgjnFEz",
        "outputId": "b70db10c-e642-47ac-b258-6118203c3637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "There are 41,218,879 total parameters in this model.\n",
            "There are 19,416,095 trainable parameters in this model.\n"
          ]
        }
      ],
      "source": [
        "# Save your model in a variable\n",
        "model = create_model()\n",
        "\n",
        "# Inspect parameters\n",
        "total_params = model.count_params()\n",
        "num_trainable_params = sum([w.shape.num_elements() for w in model.trainable_weights])\n",
        "\n",
        "print(f\"There are {total_params:,} total parameters in this model.\")\n",
        "print(f\"There are {num_trainable_params:,} trainable parameters in this model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDLvxCz5nnNV"
      },
      "outputs": [],
      "source": [
        "class EarlyStoppingCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs['accuracy']>0.85:\n",
        "            self.model.stop_training = True\n",
        "            print(\"\\nReached 99.9% accuracy so cancelling training!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/Project/Dataset'\n",
        "checkpoint_prefix = f\"{checkpoint_dir}/ckpt\""
      ],
      "metadata": {
        "id": "xpRxS1oPwG5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "Im06CbK_wUXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02mmM5OG-mTG",
        "outputId": "5ba4ba69-df24-4ffc-d7c8-b8211c5a6324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from /content/drive/MyDrive/Project/Dataset/ckpt\n"
          ]
        }
      ],
      "source": [
        "# Muat bobot dari checkpoint terakhir\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if latest_checkpoint:\n",
        "    print(f\"Loading weights from {latest_checkpoint}\")\n",
        "    model.load_weights(latest_checkpoint)\n",
        "else:\n",
        "    print(\"No checkpoint found. Training from scratch.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8BxXU3pdPZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cec2eb4-f6ca-4d71-fce1-02dcb167616f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "285/285 [==============================] - ETA: 0s - loss: 0.8232 - accuracy: 0.8049\n",
            "Epoch 1: val_loss did not improve from 1.04000\n",
            "285/285 [==============================] - 472s 2s/step - loss: 0.8232 - accuracy: 0.8049 - val_loss: 1.0998 - val_accuracy: 0.7288\n",
            "Epoch 2/5\n",
            "285/285 [==============================] - ETA: 0s - loss: 0.7995 - accuracy: 0.8065\n",
            "Epoch 2: val_loss did not improve from 1.04000\n",
            "285/285 [==============================] - 471s 2s/step - loss: 0.7995 - accuracy: 0.8065 - val_loss: 1.4604 - val_accuracy: 0.7308\n",
            "Epoch 3/5\n",
            "285/285 [==============================] - ETA: 0s - loss: 0.8642 - accuracy: 0.8060\n",
            "Epoch 3: val_loss improved from 1.04000 to 1.01737, saving model to /content/drive/MyDrive/Project/Dataset/ckpt\n",
            "285/285 [==============================] - 470s 2s/step - loss: 0.8642 - accuracy: 0.8060 - val_loss: 1.0174 - val_accuracy: 0.7560\n",
            "Epoch 4/5\n",
            "285/285 [==============================] - ETA: 0s - loss: 0.7855 - accuracy: 0.8113\n",
            "Epoch 4: val_loss did not improve from 1.01737\n",
            "285/285 [==============================] - 472s 2s/step - loss: 0.7855 - accuracy: 0.8113 - val_loss: 1.1132 - val_accuracy: 0.7530\n",
            "Epoch 5/5\n",
            "285/285 [==============================] - ETA: 0s - loss: 0.8287 - accuracy: 0.8062\n",
            "Epoch 5: val_loss did not improve from 1.01737\n",
            "285/285 [==============================] - 469s 2s/step - loss: 0.8287 - accuracy: 0.8062 - val_loss: 1.2496 - val_accuracy: 0.7409\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=5,\n",
        "    callbacks=[checkpoint_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsMSR1HYT7d6"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/Project/Dataset/model2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKMEeGWDruCG",
        "outputId": "8e64befc-00e4-43b8-bd9c-a6c6e36ebf8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training folder extensions:\n",
            "  /content/drive/MyDrive/Project/Dataset/train: set()\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kunyit: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/serai: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/vanili: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/lada: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/lengkuas: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/wijen: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kluwek: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/saffron: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/pala: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kayu manis: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/jinten: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kemukus: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/jahe: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kencur: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kayu secang: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kemiri: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/kapulaga: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/daun salam: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/daun ketumbar: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/asam jawa: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/bawang bombai: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/daun kemangi: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/biji ketumbar: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/daun jeruk: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/bunga lawang: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/bawang merah: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/bukan rempah: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/cengkeh: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/bawang putih: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/adas: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/train/andaliman: {'.jpeg'}\n",
            "\n",
            "Validation folder extensions:\n",
            "  /content/drive/MyDrive/Project/Dataset/test: set()\n",
            "  /content/drive/MyDrive/Project/Dataset/test/serai: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/lada: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/pala: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/vanili: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/wijen: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kunyit: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/lengkuas: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/saffron: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/daun salam: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/jahe: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kemukus: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kapulaga: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kluwek: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kayu secang: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/jinten: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kemiri: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kayu manis: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/kencur: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/cengkeh: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/bawang bombai: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/daun kemangi: {'.jpeg', '.jpg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/bunga lawang: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/daun jeruk: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/biji ketumbar: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/daun ketumbar: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/bukan rempah: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/bawang putih: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/bawang merah: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/adas: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/asam jawa: {'.jpeg'}\n",
            "  /content/drive/MyDrive/Project/Dataset/test/andaliman: {'.jpeg', '.jpg'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "def list_extensions_recursive(folder_path):\n",
        "    \"\"\"Lists all unique file extensions in a given folder and its subfolders.\n",
        "\n",
        "    Args:\n",
        "        folder_path: The path to the folder.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary mapping subfolder paths to sets of unique extensions found within them.\n",
        "    \"\"\"\n",
        "    extensions_by_folder = {}\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        extensions = set()\n",
        "        for file_name in files:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            extension = pathlib.Path(file_path).suffix.lower()\n",
        "            extensions.add(extension)\n",
        "        extensions_by_folder[root] = extensions  # Store extensions for this subfolder\n",
        "    return extensions_by_folder\n",
        "\n",
        "# Replace 'path/to/your/training/folder' and 'path/to/your/validation/folder' with the actual paths\n",
        "training_folder = TRAIN_DIR\n",
        "validation_folder = TEST_DIR\n",
        "\n",
        "training_extensions = list_extensions_recursive(training_folder)\n",
        "validation_extensions = list_extensions_recursive(validation_folder)\n",
        "\n",
        "print(\"Training folder extensions:\")\n",
        "for folder, extensions in training_extensions.items():\n",
        "    print(f\"  {folder}: {extensions}\")\n",
        "\n",
        "print(\"\\nValidation folder extensions:\")\n",
        "for folder, extensions in validation_extensions.items():\n",
        "    print(f\"  {folder}: {extensions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stxaaKBFsDQU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def check_images(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = tf.io.read_file(file_path)\n",
        "                img = tf.image.decode_image(img)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading {file_path}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "check_images(TEST_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Au0fE1nM9nkE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def verify_and_convert_image(file_path):\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            img.verify()  # Verify that it is, in fact, an image\n",
        "            img = Image.open(file_path)  # Reopen the image file\n",
        "            if img.mode == 'RGBA' or img.mode not in ['RGB', 'L']:\n",
        "                img = img.convert('RGB')\n",
        "            if img.format != 'JPEG':\n",
        "                img.save(file_path, format='JPEG')  # Save it as a proper JPEG\n",
        "            #print(f\"Verified and converted: {file_path}\")\n",
        "    except (IOError, SyntaxError) as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "\n",
        "def process_images_in_directory(root_dir):\n",
        "    for subdir, _, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(subdir, file)\n",
        "            if file_path.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):\n",
        "                verify_and_convert_image(file_path)\n",
        "\n",
        "# Example usage\n",
        "root_dir = TRAIN_DIR # Replace with the path to your dataset\n",
        "process_images_in_directory(root_dir)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}